#+Title: Revelation Principle
#+AUTHOR:    Christoph Schottm√ºller
#+Date: 

#+LANGUAGE:  en
#+OPTIONS:   H:2 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport


#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: 
#+BEAMER_FRAME_LEVEL: 2
#+latex_header: \mode<beamer>{\useinnertheme{rounded}\usecolortheme{rose}\usecolortheme{dolphin}\setbeamertemplate{navigation symbols}{}\setbeamertemplate{footline}[frame number]{}}
#+latex_header: \mode<beamer>{\usepackage{amsmath}\usepackage{ae,aecompl,amsthm,amssymb}\usepackage{sgamevar,tikz}\usetikzlibrary{trees}}
#+LATEX_HEADER:\let\oldframe\frame\renewcommand\frame[1][allowframebreaks]{\oldframe[#1]}
#+LATEX_HEADER: \setbeamertemplate{frametitle continuation}[from second]

# note: in 2018 I finished 10 minutes early (maybe add another examples, e.g. auction or bilateral trade next time)

* The Mechanism Design Problem
** What is Mechanism Design?
- people ("agents") have private information
- which game do you have to let agents play to get the outcome that you want?


** The Mechanism Design Problem: Example
*** Example: A public project 				     :B_exampleblock:
    :PROPERTIES:
    :BEAMER_env: exampleblock
    :END:
 - $I$ residents of an island decide whether to build a bridge to the main land which costs $c$
  - each resident knows how much he values the bridge himself but does not know the others' valuation
  - resident $i$ has valuation $\theta_{i}$ and wealth $m_{i}$
  - if resident $i$ has to pay $t_{i}$ his utility is $m_{i}+\theta_{i}-t_{i}$
- When is it efficient to build a bridge?
- How should the decision and payments be organized if we want to achieve efficiency?

** The Mechanism Design Problem: Example
*** Example: A public project (continued) 		     :B_exampleblock:
    :PROPERTIES:
    :BEAMER_env: exampleblock
    :END:
- Egalitarian contribution rule:
  - everyone is asked for his valuation
  - the bridge is built if the sum of the announced valuations is greater than c 
  - if the bridge is built, everyone pays $c/I$
- Does the egalitarian contribution rule lead to efficiency?
- Would you announce your true valuation?

# Example on blackboard: 2 agents and the valuation of agent 1 is 4. The costs are 5. You are agent 2 and your valuation is 2 (but agent 1 does not know whether your valuation is 0,2 or 4). What will you do?


** The Mechanism Design Problem: General formulation 
- $I$ agents 
- collective choice from a set $X$ of alternatives
- nature assigns to each agent $i$ his type $\theta_i\in\Theta_{i}$ which is $i$'s private information
- the type vector $\theta=(\theta_1,\dots,\theta_{I})$ is distributed according to a distribution $\phi$ 
- each agent has a utility function $u_{i}(x,\theta_{i})$ that depends on the collective choice and his type

** The Mechanism Design Problem: General formulation 
*** Social choice function				       :B_definition:
    :PROPERTIES:
    :BEAMER_env: definition
    :END:
A \emph{social choice function} is a function $f:\Theta_{1}\times \dots\times\Theta_{I}\rightarrow X$ that assigns to each profile of types $(\theta_{1},\dots,\theta_{I})$ a collective choice $f(\theta_{1},\dots,\theta_{I})\in X$.
*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:
- roughly:
   - social choice function gives a desired outcome as a function of the agents' types



** The mechanism design problem: Example in the general formulation
- an outcome $x\in X$: $(y,t_1,\dots,t_I)$ 
   - $y=1$ if bridge built and 0 otherwise
   - $t_i$ is payment by player $i$
   - costs have to be covered: $\sum_i t_i\geq y*c$
- $X=\{(y,t_1,\dots,t_I)\in\Re^{I+1}: y\in\{0,1\},\sum_i t_i\geq y*c\}$
- $u_i(x,\theta_i)=m_i+y*\theta_i-t_i$
- example social choice function:
   $$f(\theta)=\begin{cases}(1,c/I,\dots,c/I)& \text{ if }\sum_i\theta_i> c\\ (0,0,\dots,0)& \text{ else }\end{cases}$$

** The Mechanism Design Problem: "mechanism"
- a mechanism is a game played by the agents
- each agent has a strategy set $S_{i}$ in this game 
*** mechanism 						       :B_definition:
    :PROPERTIES:
    :BEAMER_env: definition
    :END:
A mechanism $\Gamma=(S_{1},\dots,S_{I},g(\cdot))$ is a collection of I strategy sets $(S_{1},\dots,S_{I})$ and an outcome function $g:S_{1}\times\dots\times S_{I}\rightarrow X$.

** The Mechanism Design Problem: "mechanism"
*** A public project (continued)				  :B_example:
    :PROPERTIES:
    :BEAMER_env: example
    :END:
- egalitarian contribution rule is a mechanism
  - $S_{i}=\Theta_{i}$ 
  - $g(s_{1},\dots,s_{I})=\begin{cases}(1,c/I,\dots,c/I) &\text{ if }\sum_{i}s_{i}>c\\(0,0,\dots,0)&\text{ else }\end{cases}$
- another mechanism is the voluntary contribution mechanism
  - everyone announces a contribution $s_{i}\in[0,\infty)$
  - bridge is built if the sum of the contributions is higher than $c$
  - everyone pays $c\frac{s_{i}}{\sum_{j}s_{j}}$ if the bridge is built
  - $S_{i}= [0,\infty)$ and $g$ is defined by $$g(s_{1},\dots,s_{I})=\begin{cases}(1,c\frac{s_{1}}{\sum_{j}s_{j}},c\frac{s_{2}}{\sum_{j}s_{j}},\dots,c\frac{s_{I}}{\sum_{j}s_{j}})&\text{ if } \sum_{j}s_{j}>c\\ (0,0,\dots,0) &\text{ else }\end{cases}$$

** The Mechanism Design Problem: "mechanism"
- Together with the type sets $(\Theta_{1},\dots,\Theta_{I})$, the distribution $\phi$ and the utility functions $(u_{1}(\cdot),\dots,u_{I}(\cdot))$, a mechanism $\Gamma$ induces the Bayesian game:
$$ \langle I,(S_{i})_{i=1,\dots,I},(\tilde{u}_{i})_{i=1,\dots,I},\Theta_{1}\times\dots\times\Theta_{I},\phi(\cdot) \rangle $$
where $\tilde{u}_{i}(s_{1},\dots , s_{I},\theta_{i})=u_{i}(g(s_{1},\dots , s_{I}),\theta_{i})$
- Bayesian game because
   - agents have to choose a strategy from their strategy set
   - through the mechanism (=rules of the game) their payoff depends on all agents' strategy choices
   - every agent is uncertain about other agents' type
** The Mechanism Design Problem: "implementing a social choice function"
*** implementing					       :B_definition:
    :PROPERTIES:
    :BEAMER_env: definition
    :END:
The mechanism $\Gamma=(S_{1},\dots,S_{I},g(\cdot))$ \emph{implements the social choice function} $f$ if there is a (Bayesian Nash) equilibrium strategy profile $(s_{1}^{*},\dots,s_{I}^{*})$ of the Bayesian game induced by $\Gamma$ such that $g(s_{1}^{*}(\theta_{1}),\dots,s_{I}^{*}(\theta_{I}))=f(\theta_{1},\dots,\theta_{I})$ for all $(\theta_{1},\dots,\theta_{I})\in\Theta_{1}\times\dots \times\Theta_{I}$.

*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:
- implements: the game has an equilibrium in which we get the desired outcome

** The Mechanism Design Problem: "implementing a social choice function"
*** A public project (continued)				  :B_example:
    :PROPERTIES:
    :BEAMER_env: example
    :END:
- consider $f$: build the bridge only if $\sum_{i}\theta_{i}>c$ and let $t_{i}=c/I$ if the bridge is built and $0$ otherwise
- we saw above that---in general---the egalitarian contribution rule does not have an equilibrium in which everyone says his true type
- $f$ is therefore not implementable by the egalitarian contribution mechanism
- Take a simple example
  - 2 agents: agent 1's valuation is $2$ and  $c=4$
  - agent 2's valuation is either 1 or 3 (private information of agent 2)
  - check: in this example, the egalitarian contribution mechanism implements $f$

** The Mechanism Design Problem: "direct revelation mechanism"
- in a direct revelation mechanism each player is directly asked to reveal his type
*** direct revelation mechanism				       :B_definition:
    :PROPERTIES:
    :BEAMER_env: definition
    :END:
A mechanism $\Gamma$ is called a \emph{direct revelation mechanism} if $S_{i}=\Theta_{i}$ and $g(\theta)=f(\theta)$.
*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:
check in the previous example: the egalitarian contribution mechanism is a direct mechanism for $f$

** The Mechanism Design Problem: "truthful implementation/incentive compatibility"
- a social choice function is *incentive compatible* if truthfully revealing one's type is (Bayesian Nash) equilibrium in the direct revelation mechanism 

*** truthfully implementable				       :B_definition:
    :PROPERTIES:
    :BEAMER_env: definition
    :END:
A social choice function $f$ is \emph{truthfully implementable} (or \emph{incentive compatible}) if the direct revelation mechanism $\Gamma=(\Theta_{1},\dots,\Theta_{I},f)$ has a (Bayesian Nash) equilibrium $(s_{1}^{*},\dots,s_{I}^{*})$ in which $s_{i}^{*}(\theta_{i})=\theta_{i}$ for all $\theta_i$ and all $i$.

*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:
- "incentive compatible" is sometimes abbreviated with "ic"

** The Mechanism Design Problem: "truthful implementation/incentive compatibility"
*** A public project (continued)				  :B_example:
    :PROPERTIES:
    :BEAMER_env: example
    :END:
- whether $f$ (egalitarian contribution) is incentive compatible depends on the setting
  - if $I=2$, $\Theta_{1}=\{2\}$, $\Theta_{2}=\{1,3\}$ and $c=4$, then $f$ is ic (no matter what $\phi$ is) (why?)
  - if $I=2$, $\Theta_{1}=\{2\}$, $\Theta_{2}=\{0,1\}$ and $c=2.5$, then $f$ is not ic (no matter what $\phi$ is) (why?)
  - if $I=2$, $\Theta_{1}=\Theta_{2}=[0,1]$, $c=1$ and $\phi$ is a uniform distribution, then $f$ is not ic (why?)


* Revelation principle

** Revelation principle (for Bayesian Nash equilibrium)

*** Revelation principle 
If there exists a mechanism $\Gamma=(S_1,\dots,S_I,g)$ implementing the social choice function $f$, then $f$ is truthfully implementable.
*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:

Proof: 
- let  $\Gamma=(S_1,\dots,S_I,g)$ implement $f$, i.e. let $\langle I,(S_{i})_{i=1,\dots,I},(\tilde{u}_{i})_{i=1,\dots,I},\Theta_{1}\times\dots\times\Theta_{I},\phi(\cdot)\rangle$ have an equilibrium $(s_1^*,\dots,s_I^*)$ such that $g(s_1^*(\theta_1),\dots,s_I^*(\theta_I))=f(\theta)$ for all $\theta$
- this means 
$$s_i^*(\theta_i)\in argmax_{s_i\in S_i}\mathbb{E}_{\theta_{-i}}\left[u_i(g(s_1^*(\theta_1),\dots,s_i,\dots,s_I^*(\theta_I)),\theta_i)|\theta_i\right]$$
$$\Rightarrow\quad\theta_i\in argmax_{\hat\theta_i\in\Theta_i}\mathbb{E}_{\theta_{-i}}\left[u_i(g(s_1^*(\theta_1),\dots,s_i^*(\hat\theta_i),\dots,s_I^*(\theta_I)),\theta_i)|\theta_i\right]$$
$$\Leftrightarrow \theta_i\in argmax_{\hat\theta_i\in\Theta_i}\mathbb{E}_{\theta_{-i}}\left[u_i(f(\theta_1,\dots,\hat\theta_i,\dots,\theta_I),\theta_i)|\theta_i\right]$$
- i.e. truthtelling is best response in direct revelation mechanism given that others tell truth \qed

** Revelation principle: relevance
- "can $f$ be implemented?" $\Leftrightarrow$ "is $f$ truthfully implementable?" $\Leftrightarrow$ "is announcing the true type equilibrium in direct revelation mechanism?"
- no need to try out many different mechanisms
- /set of implementable social choice functions/ is set of social choice functions for which the direct revelation mechanism is incentive compatible
- focus of mechanism design on direct revelation mechanism and incentive compatibility

- caveat:  there may be other equilibria not corresponding to $f$ as well!
